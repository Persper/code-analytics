{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#coding=utf-8\n",
    "import xml.dom.minidom\n",
    "import re\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove(data):\n",
    "    data = re.sub(r'</?p>', \"\", data)\n",
    "    data = re.sub(r'</?tt>', \"\", data)\n",
    "    data = re.sub(r'<br/>', \"\", data)\n",
    "    data = re.sub(r'\\<a.*?\\>', \"\", data)\n",
    "    data = re.sub(r'</a>', \"\", data)\n",
    "    data = re.sub(r'\\<div.*?\\>', \"\", data)\n",
    "    data = re.sub(r'\\</div\\>', \"\", data)\n",
    "    data = re.sub(r'\\<pre.*?\\>', \"\", data)\n",
    "    data = re.sub(r'\\</pre\\>', \"\", data)\n",
    "    data = re.sub(r'\\<span.*?\\>', \"\", data)\n",
    "    data = re.sub(r'\\</span\\>', \"\", data)\n",
    "    data = re.sub(r'\\<ul.*?\\>', \"\", data)\n",
    "    data = re.sub(r'</ul\\>', \"\", data)\n",
    "    data = re.sub(r'\\<table.*?\\>', \"\", data)\n",
    "    data = re.sub(r'\\</table\\>', \"\", data)\n",
    "    data = re.sub(r'\\<td.*?\\>', \"\", data)\n",
    "    data = re.sub(r'\\</td\\>', \"\", data)\n",
    "    data = re.sub(r'\\<th.*?\\>', \"\", data)\n",
    "    data = re.sub(r'\\</th\\>', \"\", data)\n",
    "    data = re.sub(r'\\</?del\\>', \"\", data)\n",
    "    data = re.sub(r'\\</?em\\>', \"\", data)\n",
    "    data = re.sub(r'\\</?h3\\>', \"\", data)\n",
    "    data = re.sub(r'\\</?li\\>', \"\", data)\n",
    "    data = re.sub(r'</?ol>', \"\", data)\n",
    "    data = re.sub(r'</?tr>', \"\", data)\n",
    "    data = re.sub(r'</?tbody>', \"\", data)\n",
    "    data = re.sub(r'\\<img.*?\\>', \"\", data)\n",
    "    data = re.sub(r'\\n', \" \", data)\n",
    "    data = re.sub(r'\\&gt\\;', \">\", data)\n",
    "    data = re.sub(r'\\&lt\\;', \"<\", data)\n",
    "    data = re.sub(r'\\&\\#91\\;', \"[\", data)\n",
    "    data = re.sub(r'\\&\\#93\\;', \"]\", data)\n",
    "    data = re.sub(r'\\&\\#8211\\;', \"-\", data)\n",
    "    data = re.sub(r'\\&amp\\;', \"&\", data)\n",
    "    data = re.sub(r'\\<200c\\>', \"\", data)\n",
    "    data = re.sub(r'\\<200b\\>', \"\", data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readInfoFromXML(parseFile):\n",
    "    \"\"\"return dataset, a list of dict data points\"\"\"\n",
    "    dp = {}\n",
    "    title = parseFile.getElementsByTagName('title')\n",
    "    for i, ti in enumerate(title):\n",
    "        if i != 0:\n",
    "            data = ti.firstChild.data\n",
    "            data = re.sub(r'\\[.*?\\]\\s', \"\", data)\n",
    "            data = remove(data)\n",
    "            dp['title'] = data\n",
    "    description = parseFile.getElementsByTagName('description')\n",
    "    for i, des in enumerate(description):\n",
    "        if i != 0 and des.firstChild != None:\n",
    "            data = remove(des.firstChild.data)\n",
    "            dp['description'] = data.encode('utf-8')\n",
    "    comments = parseFile.getElementsByTagName('comment')\n",
    "    for i, com in enumerate(comments):\n",
    "        data = remove(com.firstChild.data)\n",
    "        dp['comment'] = data.encode('utf-8')\n",
    "    type = parseFile.getElementsByTagName('type')\n",
    "    for i, typ in enumerate(type):\n",
    "        dp['type'] = typ.firstChild.data.encode('utf-8')\n",
    "    priority = parseFile.getElementsByTagName('priority')\n",
    "    for i, pri in enumerate(priority):\n",
    "        dp['priority'] = pri.firstChild.data.encode('utf-8')\n",
    "    return dp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getInfoFromXML(fromDir, path):\n",
    "    fromFile = os.path.join('%s%s' % (fromDir, path))\n",
    "    dom = xml.dom.minidom.parse(fromFile)\n",
    "    parseFile = dom.documentElement\n",
    "    return readInfoFromXML(parseFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Number of issues:', 4729)\n",
      "Percentage of bugs: 0.41\n"
     ]
    }
   ],
   "source": [
    "def getUsefulInfo(filepath):\n",
    "    dataset = []\n",
    "    pathDir =  os.listdir(filepath)\n",
    "    subName = \"SPARK\"              # now only deal with the spark issue \n",
    "    invalidName = \"invalid\"\n",
    "    numFiles = 0\n",
    "    for allDir in pathDir:\n",
    "        if subName in allDir:\n",
    "            if invalidName in allDir:\n",
    "                continue\n",
    "            dp = getInfoFromXML(filepath, allDir)\n",
    "            dataset.append(dp)\n",
    "            numFiles += 1\n",
    "    return dataset\n",
    "\n",
    "filePath = \"./data-jira/spark-issues/\"\n",
    "datasets = {'spark':getUsefulInfo(filePath)}\n",
    "total = len(datasets['spark'])\n",
    "print('Number of issues:', len(datasets['spark']))\n",
    "print('Percentage of bugs: %.2f' % (1.0 * sum([1 for dp in datasets['spark'] if dp['type'] == 'Bug']) / len(datasets['spark'])))\n",
    "#datasets['spark']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Number of issues left: ', 4173)\n"
     ]
    }
   ],
   "source": [
    "last_total = sum([len(datasets['spark'])])\n",
    "for dp in datasets['spark']:\n",
    "    if 'description' not in dp:\n",
    "        datasets['spark'].remove(dp)\n",
    "total = len(datasets['spark'])  \n",
    "while last_total != total:\n",
    "    last_total = sum([len(datasets['spark'])])\n",
    "    for dp in datasets['spark']:\n",
    "        if 'description' not in dp:\n",
    "            datasets['spark'].remove(dp)\n",
    "    total = len(datasets['spark'])\n",
    "print('Number of issues left: ', total) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Number of issues left: ', 4109)\n"
     ]
    }
   ],
   "source": [
    "last_total = sum([len(datasets['spark'])])\n",
    "for dp in datasets['spark']:\n",
    "    if 'comment' not in dp:\n",
    "        datasets['spark'].remove(dp)\n",
    "total = len(datasets['spark'])  \n",
    "while last_total != total:\n",
    "    last_total = sum([len(datasets['spark'])])\n",
    "    for dp in datasets['spark']:\n",
    "        if 'comment' not in dp:\n",
    "            datasets['spark'].remove(dp)\n",
    "    total = len(datasets['spark'])\n",
    "print('Number of issues left: ', total) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(datasets, open('data-jira/spark-issues.pickle', 'wb'), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
