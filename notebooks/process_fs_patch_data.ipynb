{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def generate_dataset(files):\n",
    "    \"\"\"return dataset, a list of dict data points\"\"\"\n",
    "    dataset = []\n",
    "    attributes = ('type', 'sub_type', 'sub_sub_type', \n",
    "                  'cons_type', 'sub_cons_type')\n",
    "    \n",
    "    re_patch_bp = re.compile(\"\"\"\\((?P<type>[bp]):\n",
    "                                (?P<sub_type>[^(->)]*)\n",
    "                                (->(?P<sub_sub_type>[^(->)\\)]*))?\n",
    "                                (->[^(->)\\)]*)*\\):\n",
    "                                \\(s:(?P<cons_type>[^(->)]*)\n",
    "                                (->(?P<sub_cons_type>[^\\)]*))?\\)\"\"\", re.VERBOSE)\n",
    "    re_patch_c = re.compile(\"\"\"\\((?P<type>c):\n",
    "                                (?P<sub_type>[^(->)]*)\n",
    "                                (->(?P<sub_sub_type>[^(->)\\)]*))?\\)\"\"\", re.VERBOSE)\n",
    "    re_patch_misc = re.compile(\"\"\"\\((?P<type>misc)->\n",
    "                                    (?P<sub_type>[^\\)]*)\\)\"\"\", re.VERBOSE)\n",
    "    re_patch_f = re.compile(\"\\((?P<type>f)\\)\")\n",
    "    \n",
    "    for fname in files:\n",
    "        with open(fname, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            \n",
    "        ptr = 0\n",
    "        while ptr <= len(lines) - 2:\n",
    "            line = lines[ptr]\n",
    "            next_line = lines[ptr + 1]\n",
    "            if line.startswith(' ') or line.startswith('\\t'):\n",
    "                try:\n",
    "                    assert(next_line.lstrip().startswith('.'))\n",
    "                except:\n",
    "                    \"\"\"\n",
    "                    print('-------- Error line ---------')\n",
    "                    print('line:%s' % line)\n",
    "                    print('next:%s' % next_line)\n",
    "                    print('-----------------------------')\n",
    "                    \"\"\"\n",
    "                    ptr += 1\n",
    "                    continue\n",
    "                dp = {}\n",
    "                dp['subject'] = line.lstrip().rstrip()\n",
    "                \n",
    "                m = re_patch_bp.search(next_line) or \\\n",
    "                    re_patch_c.search(next_line) or \\\n",
    "                    re_patch_misc.search(next_line) or \\\n",
    "                    re_patch_f.search(next_line)\n",
    "                if m != None:\n",
    "                    gd = m.groupdict()\n",
    "                    for attr in attributes:\n",
    "                        if attr in gd:\n",
    "                            dp[attr] = gd[attr]\n",
    "                    dataset.append(dp)\n",
    "                    ptr += 2\n",
    "                else:\n",
    "                    # skip lines with multiple sub_types and consequences\n",
    "                    ptr += 1\n",
    "            else:\n",
    "                ptr += 1\n",
    "            \n",
    "    return dataset\n",
    "\n",
    "fss = ['ext3', 'ext4', 'btrfs', 'xfs', 'jfs', 'reiserfs']\n",
    "datasets = {fs : generate_dataset(['../data/fs-patch/%s-patch' % fs]) for fs in fss}\n",
    "total = 0\n",
    "for fs in fss:\n",
    "    total += len(datasets[fs])\n",
    "    print('------ %s -------' % fs)\n",
    "    print('Number of patches:', len(datasets[fs]))\n",
    "    print('Percentage of bugs: %.2f' % (sum([1 for dp in datasets[fs] if dp['type'] == 'b']) / len(datasets[fs])))\n",
    "    print()\n",
    "print('Number of patches in total:', total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supplement Data With Info from Linux Repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from git import Repo\n",
    "r = Repo('../repos/linux-kernel')\n",
    "commits = list(r.iter_commits(rev='efd375d7ab44f68d97e6fb7582bb2af9f6d7f9f0..v3.0'))\n",
    "print('Number of commits to scan: ', len(commits))\n",
    "subject_to_sha = {}\n",
    "for commit in commits:\n",
    "    subject = commit.message.split('\\n', 1)[0].lstrip().rstrip()\n",
    "    subject_to_sha[subject] = commit.binsha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from git import Commit\n",
    "from graphs.patch_parser import PatchParser\n",
    "\n",
    "count = 0\n",
    "parser = PatchParser()\n",
    "print('-----------------------------------------------')\n",
    "print('------- Patches not matched to a commit -------')\n",
    "print('-----------------------------------------------')\n",
    "for fs in fss:\n",
    "    for dp in datasets[fs]:\n",
    "        if dp['subject'] in subject_to_sha:\n",
    "            c = Commit(r, subject_to_sha[dp['subject']])\n",
    "            diff_index = c.diff(c.parents[0], create_patch=True, R=True)\n",
    "            num_adds, num_dels = 0, 0\n",
    "            for diff in diff_index:\n",
    "                additions, deletions = parser.parse(diff.diff.decode('utf-8', 'replace'))\n",
    "                for a in additions:\n",
    "                    num_adds += a[1]\n",
    "                for d in deletions:\n",
    "                    num_dels += (d[1] - d[0] + 1)\n",
    "                \n",
    "            dp['message'] = c.message\n",
    "            dp['num_files'] = len(diff_index)\n",
    "            dp['num_adds'] = num_adds\n",
    "            dp['num_dels'] = num_dels\n",
    "\n",
    "            count += 1\n",
    "        else:\n",
    "            print(dp['subject'])\n",
    "print('Number of patches matched: ', count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correct Misspelled Bug Consequence Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for fs in fss:\n",
    "    for dp in datasets[fs]:\n",
    "        if dp['type'] == 'b' and dp['cons_type'] == 'corrpution':\n",
    "            dp['cons_type'] = 'corruption'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Data for Future Convenience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(datasets, open(\"../data/fs-patch/fs_datasets.pickle\", 'wb'), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
