{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import classifier\n",
    "from classifier import binary_bug, multi_patch_type, limited_patch_type, only_bug_filter, stem, lemmatize\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "datasets = pickle.load(open('../data/fs-patch.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fss = ['ext3', 'ext4', 'btrfs', 'xfs', 'jfs', 'reiserfs']\n",
    "exp = classifier.Classifier(datasets, fss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Classification of Bug Fix Patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only using frc\n",
    "exp.run(binary_bug, LinearSVC, use_text=False, use_frc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only using text (TF * IDF)\n",
    "exp.run(binary_bug, LinearSVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only using text (TF * BNS)\n",
    "exp.run(binary_bug, LinearSVC, use_bns=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using both text (TF * IDF) and frc\n",
    "exp.run(binary_bug, LinearSVC, use_frc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using both text (TF * BNS) and frc\n",
    "exp.run(binary_bug, LinearSVC, use_bns=True, use_frc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using both text (TF * IDF) and frc\n",
    "# drop terms with frequency lower than min_df\n",
    "exp.run(binary_bug, LinearSVC, min_df=3, use_frc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using both text (TF * BNS) and frc\n",
    "# drop terms with frequency lower than min_df\n",
    "exp.run(binary_bug, LinearSVC, use_bns=True, min_df=3, use_frc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using both stemmed text (TF * BNS) and frc\n",
    "exp.run(binary_bug, LinearSVC, use_bns=True, use_frc=True, tokenizer=stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using both lemmatized text (TF * BNS) and frc\n",
    "exp.run(binary_bug, LinearSVC, use_bns=True, use_frc=True, tokenizer=lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using both text (TF * BNS) and frc\n",
    "# select top k features by mutual information\n",
    "exp.run(binary_bug, LinearSVC, use_bns=True, use_frc=True, k=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Class Classification of Patch Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only using frc\n",
    "exp.run(multi_patch_type, LinearSVC, use_text=False, use_frc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only using text (TF * IDF)\n",
    "exp.run(multi_patch_type, LinearSVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only using text (TF * BNS)\n",
    "exp.run(multi_patch_type, LinearSVC, use_bns=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using both text (TF * IDF) and frc\n",
    "exp.run(multi_patch_type, LinearSVC, use_frc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using both text (TF * BNS) and frc\n",
    "exp.run(multi_patch_type, LinearSVC, use_bns=True, use_frc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using both text (TF * BNS) and frc\n",
    "# drop terms with frequency lower than min_df\n",
    "exp.run(multi_patch_type, LinearSVC, use_bns=True, min_df=3, use_frc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using both text (TF * BNS) and frc\n",
    "# select top k features by mutual information\n",
    "exp.run(multi_patch_type, LinearSVC, use_bns=True, use_frc=True, k=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Class Classification of Bug Consequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only using text (TF * IDF)\n",
    "exp.run(multi_bug_cons, LinearSVC, dp_filter=only_bug_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only using text (TF * BNS)\n",
    "exp.run(multi_bug_cons, LinearSVC, dp_filter=only_bug_filter, use_bns=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using both text (TF * IDF) and frc\n",
    "exp.run(multi_bug_cons, LinearSVC, dp_filter=only_bug_filter, use_frc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using both text (TF * BNS) and frc\n",
    "exp.run(multi_bug_cons, LinearSVC, dp_filter=only_bug_filter, \n",
    "        use_bns=True, use_frc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using both bigram text (TF * BNS) and frc\n",
    "exp.run(multi_bug_cons, LinearSVC, dp_filter=only_bug_filter, \n",
    "        use_bns=True, use_frc=True, ngram_range=(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only using text (TF * IDF)\n",
    "# select top k features by mutual information\n",
    "exp.run(multi_bug_cons, LinearSVC, dp_filter=only_bug_filter, k=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explaning Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "pp = pprint.PrettyPrinter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explaning random forest classifier\n",
    "def rank_features_by_importance(exp, top_n=20):\n",
    "    if 'feature_importances_' in dir(exp.classifiers['ext3']):\n",
    "        for fs in fss:\n",
    "            print('------- important features for %s -------' % fs)\n",
    "            truncated_importances = map(lambda x: '%.4f' % x, exp.classifiers[fs].feature_importances_)\n",
    "            pp.pprint(sorted(zip(truncated_importances, exp.feature_labels[fs]), reverse=True)[:top_n])\n",
    "    else:\n",
    "        print(\"classifiers don't have attribute feature_importance_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_features_by_importance(exp, top_n=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explaining SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explaining linear SVM classifier\n",
    "def rank_features_by_weight(classifiers, classes, feature_labels, \n",
    "                            top_n=20, individual_class=False):\n",
    "    \"\"\"Rank features by the absolute value of associated primal weight\n",
    "    \n",
    "    Args:\n",
    "        classifiers: A dictionary, with key being the file system name\n",
    "            and value being the corresponding classifier.\n",
    "        classes: A list of class labels.\n",
    "        feature_labels: A dictionary of list of feature names, each key\n",
    "            is a file system name, features are in the order as classifier\n",
    "            sees them.\n",
    "        top_n: An integer, specifies number of top features to print.\n",
    "        individual_class: A boolean value, whether use sum of absolute weights \n",
    "            across classes. In binary tasks, this value doesn't matter.\n",
    "    \"\"\"\n",
    "    \n",
    "    fss = list(classifiers.keys())\n",
    "    if 'coef_' in dir(classifiers[fss[0]]):\n",
    "        for fs in fss:\n",
    "            print('------- %s -------' % fs)\n",
    "            if individual_class:\n",
    "                coef = classifiers[fs].coef_\n",
    "                for i in range(coef.shape[0]):\n",
    "                    print('\\t------ %s ------' % classes[i])\n",
    "                    # print('\\t------  ------')\n",
    "                    order = np.argsort(np.absolute(coef[i]))\n",
    "                    pp.pprint(np.array(feature_labels[fs])[order][-top_n:])\n",
    "                print()\n",
    "            else:\n",
    "                coef = classifiers[fs].coef_\n",
    "                num_features = coef.shape[1]\n",
    "                abs_coef_sum = np.zeros(num_features)\n",
    "                for i in range(coef.shape[0]):\n",
    "                    abs_coef_sum += np.absolute(coef[i])\n",
    "                order = np.argsort(abs_coef_sum)\n",
    "                pp.pprint(np.array(feature_labels[fs])[order][-top_n:])\n",
    "    else:\n",
    "        print(\"classifiers don't have attribute coef_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_features_by_weight(exp.classifiers, np.unique(exp.train_targets['ext3']), \n",
    "                        exp.feature_labels, top_n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_features_by_weight(exp.classifiers, np.unique(exp.train_targets['ext3']), \n",
    "                        exp.feature_labels, top_n=20, individual_class=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "c = make_pipeline(vectorizers['ext3'], classifiers['ext3'])\n",
    "print(c.predict_proba([test_texts['ext3'][1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lime.lime_text import LimeTextExplainer\n",
    "class_names = ['not-bug', 'bug']\n",
    "explainer = LimeTextExplainer(class_names=class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain_pred(idx, fs):\n",
    "    c = make_pipeline(vectorizers[fs], classifiers[fs])\n",
    "    exp = explainer.explain_instance(test_texts[fs][idx].lower(), c.predict_proba, num_features=8)\n",
    "    print('Patch id: %d' % idx)\n",
    "    print('Probability(bug) =', c.predict_proba([test_texts[fs][idx]])[0,1])\n",
    "    print('True class: %s' % class_names[test_targets[fs][idx]])\n",
    "    print('Text: %s' % test_texts[fs][idx])\n",
    "    pp.pprint(exp.as_list())\n",
    "    # exp.show_in_notebook(text=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "fs = 'ext3'\n",
    "c = make_pipeline(vectorizers[fs], classifiers[fs])\n",
    "for i in range(len(test_texts[fs])):\n",
    "    if ('fix' not in test_texts[fs][i].lower() \n",
    "        and c.predict_proba([test_texts[fs][i]])[0,1] > 0.5\n",
    "        and test_targets[fs][i] == 1):\n",
    "        explain_pred(i, fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keyword 'fix'\n",
    "for i in [22, 24]:\n",
    "    explain_pred(i, 'ext3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when keyword 'fix' is absent\n",
    "for i in [23, 25]:\n",
    "    explain_pred(i, 'ext3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interesting case\n",
    "for i in [5, 26]:\n",
    "    explain_pred(i, 'ext3')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
