{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.auto_scroll_threshold = 9999;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies and set default alpha value\n",
    "import math\n",
    "import pickle\n",
    "import pprint\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from graphs.call_commit_graph import CallCommitGraph\n",
    "from scipy.stats import spearmanr, kendalltau\n",
    "\n",
    "default_alpha = 0.8\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "def write_hash_to_csv(hh, fname):\n",
    "    with open(fname, \"w+\") as f:\n",
    "        for key, value in hh.items():\n",
    "            f.write(str(key) + ',' + str(value) + '\\n')\n",
    "            \n",
    "def write_dots_to_csv(xs, ys, fname, header):\n",
    "    with open(fname, \"w+\") as f:\n",
    "        f.write(header)\n",
    "        for x, y in zip(xs, ys):\n",
    "            f.write(str(x) + ',' + str(y) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Call-Commit Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set your own pickle_path (relative to this notebook) and repo_name\n",
    "\n",
    "# pickle_path = \"../data/httpd-finished.pickle\"\n",
    "# repo_name = \"httpd\"\n",
    "\n",
    "#pickle_path = \"../data/call-commit-graphs/flink-1st-7100.pickle\"\n",
    "#repo_name = \"flink\"\n",
    "\n",
    "#pickle_path = \"../data/call-commit-graphs/kafka-finished.pickle\"\n",
    "#repo_name = \"kafka\"\n",
    "\n",
    "pickle_path = \"../data/call-commit-graphs/systemml-finished.pickle\"\n",
    "repo_name = \"systemml\"\n",
    "\n",
    "repo_path = \"../repos/\" + repo_name\n",
    "with open(pickle_path, \"rb\") as pf:\n",
    "    ccg = pickle.load(pf)\n",
    "ccg.set_repo_path(repo_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DevRank Share"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run DevRank on Call-Commit Graph and them map developer name to share\n",
    "# WARNING: this code doesn't work in the case that two developers have same name\n",
    "def get_name_to_share(alpha, sha_to_type={}, coefs=[1, 1, 1, 1]):\n",
    "    sorted_share, email_to_name = ccg.devrank_developers(alpha, sha_to_type=sha_to_type, coefs=coefs)\n",
    "    name_to_share = {}\n",
    "    for email, share in sorted_share:\n",
    "        name = email_to_name[email]\n",
    "        if name in name_to_share:\n",
    "            name_to_share[name] += share\n",
    "        else:\n",
    "            name_to_share[name] = share\n",
    "    share_sum = 0\n",
    "    for n in name_to_share:\n",
    "        share_sum += name_to_share[n]\n",
    "    for n in name_to_share:\n",
    "        name_to_share[n] = name_to_share[n] / share_sum\n",
    "    return name_to_share, email_to_name\n",
    "    \n",
    "name_to_share, email_to_name = get_name_to_share(default_alpha)\n",
    "\n",
    "# Uncomment the following line to see sorted results\n",
    "# sorted(name_to_share.items(), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write DevRank result of different alphas to csv\n",
    "for alpha in np.arange(0.1, 1.0, 0.1):\n",
    "    name_to_share, _ = get_name_to_share(alpha)\n",
    "    write_hash_to_csv(name_to_share, \"../temp/%s-devrank-%.2f.csv\" % (repo_name, alpha))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LocRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract LOC info from ccg.history\n",
    "email_to_loc = {}\n",
    "for sha in ccg.history:\n",
    "    actor = ccg.repo.commit(sha).author\n",
    "    email = actor.email\n",
    "    if email not in email_to_loc:\n",
    "        email_to_loc[email] = 0\n",
    "    for func in ccg.history[sha]:\n",
    "        email_to_loc[email] += ccg.history[sha][func]\n",
    "        \n",
    "# WARNING: this code doesn't work in the case that two people have same name\n",
    "name_to_loc = {}\n",
    "for email, loc in email_to_loc.items():\n",
    "    name = email_to_name[email]\n",
    "    if name in name_to_loc:\n",
    "        name_to_loc[name] += loc\n",
    "    else:\n",
    "        name_to_loc[name] = loc\n",
    "        \n",
    "# Uncomment the following line to see sorted results\n",
    "# sorted(name_to_loc.items(), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write LocRank result to csv\n",
    "write_hash_to_csv(name_to_loc, \"../temp/%s-loc.csv\" % repo_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CommitRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract number of commits info from ccg.history\n",
    "email_to_noc = {}\n",
    "for sha in ccg.history:\n",
    "    actor = ccg.repo.commit(sha).author\n",
    "    email = actor.email\n",
    "    if email not in email_to_noc:\n",
    "        email_to_noc[email] = 0\n",
    "    email_to_noc[email] += 1\n",
    "    \n",
    "# WARNING: this code doesn't work in the case that two people have same name\n",
    "name_to_noc = {}\n",
    "for email, noc in email_to_noc.items():\n",
    "    name = email_to_name[email]\n",
    "    if name in name_to_noc:\n",
    "        name_to_noc[name] += noc\n",
    "    else:\n",
    "        name_to_noc[name] = noc\n",
    "        \n",
    "# Uncomment the following line to see sorted results\n",
    "#sorted(name_to_noc.items(), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_hash_to_csv(name_to_noc, \"../temp/%s-noc.csv\" % repo_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Gini Coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "pwd = os.path.abspath('../')\n",
    "if pwd not in sys.path: sys.path.append(pwd)\n",
    "\n",
    "import numpy as np\n",
    "from tools.excel_charts.gini.gini import gini\n",
    "\n",
    "def get_gini(name_to_values):\n",
    "    return gini(np.array([float(x) for x in name_to_values.values()]))\n",
    "\n",
    "def get_gini_top(name_to_values, percent):\n",
    "    shares = sorted([float(x) for x in name_to_values.values()], reverse=True)\n",
    "    return gini(np.array(shares[:int(len(shares) * percent)]))\n",
    "\n",
    "noc_gini = get_gini(name_to_noc)\n",
    "loc_gini = get_gini(name_to_loc)\n",
    "for a in np.arange(0.0, 1.0, 0.1):\n",
    "    n2s, _ = get_name_to_share(a)\n",
    "    print(a, noc_gini, loc_gini, get_gini(n2s), get_gini_top(n2s, 0.2), sep=',')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Validation of Analysis Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If a person gets no share, he/she must have made no contribution\n",
    "ccg.update_shares(default_alpha)\n",
    "for sha in ccg.history:\n",
    "    if ccg.share[sha] == 0:\n",
    "        try:\n",
    "            assert(len(ccg.history[sha]) == 0)\n",
    "        except:\n",
    "            import pdb\n",
    "            pdb.set_trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out number of commits analyzed, manually check it against total number of commits on github\n",
    "print(\"Number of commits analyzed: \", len(ccg.visited))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all distinct author and committer emails/names\n",
    "# Number of distinct committer emails is also the upper bound for number of committers)\n",
    "all_commits = list(ccg.repo.iter_commits())\n",
    "author_emails = set()\n",
    "author_names = set()\n",
    "committer_emails = set()\n",
    "committer_names = set()\n",
    "for commit in all_commits:\n",
    "    author_emails.add(commit.author.email)\n",
    "    author_names.add(commit.author.name)\n",
    "    committer_emails.add(commit.committer.email)\n",
    "    committer_names.add(commit.committer.name)\n",
    "print(\"Number of distinct author emails: \", len(author_emails))\n",
    "print(\"Number of distinct author names: \", len(author_names))\n",
    "print(\"Number of distinct committer emails: \", len(committer_emails))\n",
    "print(\"Number of distinct committer names: \", len(committer_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Developer Role from Apache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# APR\n",
    "# https://projects.apache.org/committee.html?apr\n",
    "# Copy the roster as a string below\n",
    "pmc_string = \"Aaron Bannert,  Brian Havard, Bradley Nicholes,  Bojan Smojver,  Branko Čibej,  Colm MacCarthaigh,  Eric Covener,  Davi Arnaut,  Dirk-Willem van Gulik,  Brian Fitzpatrick,  Guenter Knauf,  Greg Ames,  Gregg Lewis Smith,  Greg Stein,  Christophe Jaillet,  Justin Erenkrantz,  Jean-Frederic Clere,  Jim Jagielski,  Joe Orton,  Cliff Woolley,  Karl Fogel,  Martin Kraemer,  Max Oliver Bowsher,  Graham Leggett,  Mladen Turk,  Nick Kew,  Paul Querna,  Rainer Jung,  Garrett Rooney,  Ruediger Pluem,  Sascha Schumann,  Stefan Fritsch,  Bill Stoddard,  Sander Striker,  Ben Collins-Sussman,  Thom May,  Jeff Trawick,  William A. Rowe Jr.,  Wilfredo Sanchez,  Yann Ylavic\"\n",
    "committer_string = \"Aaron Bannert,  Allan K. Edwards,  Ben Laurie,  Brian Havard,  Bradley Nicholes,  Bojan Smojver,  Branko Čibej,  Brian Pane,  Chuck Murcko,  Jean-Jacques Clar,  Ken Coar,  Colm MacCarthaigh,  Eric Covener,  Davi Arnaut,  Dirk-Willem van Gulik,  Doug MacEachern,  David Reid,  Tony Finch,  Roy T. Fielding,  Brian Fitzpatrick,  Guenter Knauf,  Greg Ames,  Gregg Lewis Smith,  Greg Stein,  Henry Jen,  Hyrum Kurt Wright,  Ian Holsman,  Issac Goldstand,  Ivan Zhakov,  Christophe Jaillet,  Justin Erenkrantz,  Jean-Frederic Clere,  Jim Jagielski,  Joe Orton,  Cliff Woolley,  Karl Fogel,  Madhusudan Mathihalli,  Martin Kraemer,  Max Oliver Bowsher,  Graham Leggett,  Mladen Turk,  André Malo,  Neil Conway,  Nick Kew,  Victor J. Orlikowski,  Philip M. Gollucci,  Daniel Earl Poirier,  Paul Querna,  Ryan Bloom,  Paul J. Reder,  Rainer Jung,  Garrett Rooney,  Ruediger Pluem,  Ralf S. Engelschall,  Sascha Schumann,  Sander Temme,  Stefan Fritsch,  Bill Stoddard,  Sander Striker,  Ben Collins-Sussman,  Takashi Sato,  Thomas J. Donovan,  Jeff Trawick,  William A. Rowe Jr.,  Wilfredo Sanchez,  Yann Ylavic\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# httpd\n",
    "# https://projects.apache.org/committee.html?httpd\n",
    "# Copy the roster as a string below\n",
    "pmc_string = \"Brian Havard,  Bradley Nicholes,  Bojan Smojver,  Ben Reser,  Brian McCallister,  Chris Darroch,  Colm MacCarthaigh,  Eric Covener,  Dirk-Willem van Gulik,  Stephen Henson,  Daniel Ruggeri,  Luca Toscano,  Roy T. Fielding,  Guenter Knauf,  Graham Phillip Dumpleton,  Greg Ames,  Gregg Lewis Smith,  Greg Stein,  Daniel Gruno,  Stefan Eissing,  Igor Galić,  Issac Goldstand,  Christophe Jaillet,  Jacob Champion,  Justin Erenkrantz,  Jean-Frederic Clere,  Jim Jagielski,  Joe Schaefer,  Joe Orton,  Kaspar Brand,  Astrid Malo,  Lars Eilebrecht,  Lucien Gentis,  Graham Leggett,  Mark J. Cox,  André Malo,  Nick Kew,  Tony Stevenson,  Philip M. Gollucci,  Paul Querna,  Rich Bowen,  Rainer Jung,  Ruediger Pluem,  Sander Temme,  Stefan Fritsch,  Steffen Land,  Jeff Trawick,  William A. Rowe Jr.,  Yann Ylavic\"\n",
    "committer_string = \"Aaron Bannert,  Andrew William John Ford,  Allan K. Edwards,  Ask Bjørn Hansen,  Andreas Steinmetz,  Ben Laurie,  Jem Berkes,  Jesus Blanco Izquierdo,  Bradley Nicholes,  Bojan Smojver,  Ben Reser,  Brian McCallister,  Chris Darroch,  Chuck Murcko,  Jean-Jacques Clar,  Ken Coar,  Colm MacCarthaigh,  Eric Covener,  Daniel Ferradal,  David Harris,  Dirk-Willem van Gulik,  Doug MacEachern,  David Shane Holden,  Stephen Henson,  Daniel Ruggeri,  Edward Lu,  Luca Toscano,  Erik Abele,  Fabien Coelho,  Roy T. Fielding,  Guenter Knauf,  Guy Ferraiolo,  Geoffrey Young,  Philippe Chiasson,  Graham Phillip Dumpleton,  Greg Ames,  Gregory Trubetskoy,  Vincent Deffontaines,  Gregg Lewis Smith,  Greg Stein,  Daniel Gruno,  Ian Holsman,  Stefan Eissing,  Igor Galić,  Issac Goldstand,  Ivan Alexis Barrera Andrade,  Jacek Prucia,  Christophe Jaillet,  Jacob Champion,  Justin Erenkrantz,  Jean-Frederic Clere,  James Paul Gallacher,  Jim Jagielski,  Jim Winstead Jr.,  Jan Kaluža,  Joe Schaefer,  Joe Orton,  John Sachs,  Jason S. Lingohr,  Hiroaki Kawai,  Kaspar Brand,  Keith Wannamaker,  Astrid Malo,  Evgeny Kotkov,  Lars Eilebrecht,  Lucien Gentis,  Luis Gil,  Jeon Jeongho,  Madhusudan Mathihalli,  Mads Toftum,  Manoj Kasichainula,  Martin Kraemer,  Matt Sergeant,  Max Kellermann,  Maxime Petazzoni,  Matthieu Estrade,  Graham Leggett,  Mark J. Cox,  Mike Rumph,  Mladen Turk,  André Malo,  Niklas Edmundsson,  Nilgun Belma Buguner,  Nick Kew,  Nicolas Lehuen,  Vincent Bray,  Victor J. Orlikowski,  Parinkumar Shah,  Tony Stevenson,  Chris Pepper,  Philip M. Gollucci,  Daniel Earl Poirier,  Ryan Pan,  Paul Querna,  Rich Bowen,  Paul J. Reder,  Rian Hunter,  Rici Lake,  Rainer Jung,  Ruediger Pluem,  Ralf S. Engelschall,  Sascha Schumann,  Sander Temme,  Stefan Fritsch,  Joshua Slive,  Ilia Soldatenko,  Steffen Land,  Steve Hay,  Sander Striker,  Stefan Sperling,  Takashi Sato,  Thomas J. Donovan,  David Wheeler,  Frank Gingras,  Jeff Trawick,  William A. Rowe Jr.,  Wilfredo Sanchez,  Yann Ylavic,  Yoshiki Hayashi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flink\n",
    "# https://projects.apache.org/committee.html?flink\n",
    "# Copy the roster as a string below\n",
    "pmc_string = \"Aljoscha Krettek,  Chesnay Schepler,  Fabian Hueske,  Alan Gates,  Greg Hogan,  Gyula Fora,  Henry Saputra,  Kostas Tzoumas,  Márton Balassi,  Maximilian Michels,  Robert Metzger,  Stephan Ewen,  Sebastian Schelter,  Till Rohrmann,  Timo Walther,  Tzu-Li (Gordon) Tai,  Ufuk Celebi,  Vasiliki Kalavri,  Daniel Warneke\"\n",
    "committer_string = \"Aljoscha Krettek,  Lungu Andra,  ChengXiang Li,  Chesnay Schepler,  Chiwan Park,  Dawid Wysakowicz,  Fabian Hueske,  Alan Gates,  Greg Hogan,  Gyula Fora,  Henry Saputra,  Jark Wu,  Jincheng Sun,  Kostas Kloudas,  Kostas Tzoumas,  Kurt Young,  Márton Balassi,  Matthias J. Sax,  Maximilian Michels,  Robert Metzger,  Paris Carbone,  Stephan Ewen,  Shaoxuan Wang,  Xiaogang Shi,  Stefan Richter,  Sebastian Schelter,  Till Rohrmann,  Theodore Vasiloudis,  Timo Walther,  Tzu-Li (Gordon) Tai,  Ufuk Celebi,  Vasiliki Kalavri,  Daniel Warneke\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kakfa\n",
    "# https://projects.apache.org/committee.html?kafka\n",
    "# Copy the roster as a string below\n",
    "pmc_string = \"Guozhang Wang,  Gwen Shapira,  Ismael Juma,  Jakob Homan,  Jason Gustafson,  Joel Jacob Koshy,  Jay Kreps,  Joe Stein,  Jun Rao,  Neha Narkhede,  Prashanth Menon\"\n",
    "committer_string = \"Alan Cabrera,  Chris Burroughs,  Damian Guy,  David Arthur,  Ewen Cheslack-Postava,  Geir Magnusson Jr,  Grant Henke,  Guozhang Wang,  Gwen Shapira,  Henry Saputra,  Ismael Juma,  Jakob Homan,  Jason Gustafson,  Joel Jacob Koshy,  Jay Kreps,  Joe Stein,  Becket Qin,  Jun Rao,  Neha Narkhede,  Owen O'Malley,  Prashanth Menon,  Phillip Rhodes,  Rajini Sivaram,  Harsha,  Sriram\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Systemml\n",
    "# https://projects.apache.org/committee.html?systemml\n",
    "# Copy the roster as a string below\n",
    "pmc_string = \"Arvind Surve,  Alexandre V. Evfimievski,  DB Tsai,  Jon Deron Eriksson,  Mike Dusenberry,  Faraz Makari,  Frederick Reiss,  Felix Schueler,  Glenn Weidner,  Holden Karau,  Henry Saputra,  Joseph Kurata Bradley,  Luciano Resende,  Matthias Boehm,  Xiangrui Meng,  Nakul Jindal,  Niketan Pansare,  Prithviraj Sen,  Patrick Wendell,  Rich Bowen,  Berthold Reinwald,  Reynold Xin,  Shirish Tatikonda\"\n",
    "committer_string = \"Arvind Surve,  Alexandre V. Evfimievski,  DB Tsai,  Jon Deron Eriksson,  Mike Dusenberry,  Faraz Makari,  Frederick Reiss,  Felix Schueler,  Glenn Weidner,  Holden Karau,  Henry Saputra,  Joseph Kurata Bradley,  Luciano Resende,  Matthias Boehm,  Xiangrui Meng,  Nakul Jindal,  Niketan Pansare,  Prithviraj Sen,  Patrick Wendell,  Rich Bowen,  Berthold Reinwald,  Reynold Xin,  Shirish Tatikonda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse roster strings\n",
    "pmc_names = set([n.strip() for n in pmc_string.split(',')])\n",
    "committer_names = set([n.strip() for n in committer_string.split(',')])\n",
    "\n",
    "# Basic statistic of the roster\n",
    "print(\"Number of PMC members: \", len(pmc_names))\n",
    "print(\"Number of committers: \", len(committer_names))\n",
    "print(\"Number of committers in PMC: \", len(pmc_names & committer_names))\n",
    "print(\"Number of committers not in PMC: \", len(committer_names) - len(pmc_names & committer_names))\n",
    "print(\"Number of PMC members not in committers: \", len(pmc_names - committer_names))\n",
    "print(\"Total number of people: \", len(committer_names) + len(pmc_names - committer_names))\n",
    "print(\"In PMC but not a committer:\\n\")\n",
    "for n in pmc_names:\n",
    "    if n not in committer_names:\n",
    "        print(\"\\t\" + n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare top k contributors given by DevRank and LocRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot out the tendency\n",
    "def get_top_k(name_to_x, k):\n",
    "    return [pair[0] for pair in sorted(name_to_x.items(), key=lambda x: x[1], reverse=True)[:k]]\n",
    "\n",
    "xs = range(1, len(name_to_share) + 1)\n",
    "ys = []\n",
    "for k in xs:\n",
    "    top_k_devrank = get_top_k(name_to_share, k)\n",
    "    top_k_locrank = get_top_k(name_to_loc, k)\n",
    "    perc = len(set(top_k_devrank).intersection(set(top_k_locrank))) / k\n",
    "    ys.append(perc)\n",
    "    \n",
    "plt.plot(xs, ys)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fig2 in the paper: Overlapping of LocRank and DevRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def figure2(alpha):\n",
    "    \"\"\"This function needs name_to_loc, so make sure you run that cell first\"\"\"\n",
    "    xs = [0.05 * i for i in range(1, 21)]\n",
    "    ys = []\n",
    "    name_to_share, _ = get_name_to_share(alpha)\n",
    "    num_authors = len(name_to_share)\n",
    "    for r in xs:\n",
    "        k = math.floor(r * num_authors)\n",
    "        top_k_devrank = get_top_k(name_to_share, k)\n",
    "        top_k_locrank = get_top_k(name_to_loc, k)\n",
    "        perc = len(set(top_k_devrank).intersection(set(top_k_locrank))) / k\n",
    "        ys.append(perc)\n",
    "\n",
    "    plt.plot(xs, ys)\n",
    "    plt.ylim((0.8, 1))\n",
    "    plt.show()\n",
    "    \n",
    "    return xs, ys\n",
    "\n",
    "for alpha in [0.2, 0.8]:\n",
    "    xs, ys = figure2(alpha)\n",
    "    write_dots_to_csv(xs, ys, \"../temp/%s-fig2-%.2f.csv\" % (repo_name, alpha), \"Percentage,Overlapping\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fig3 in the paper: Developers' relative share changes between LocRank and DevRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def figure3(alpha):\n",
    "    \"\"\"This function needs name_to_loc, so make sure you run that cell first\"\"\"\n",
    "    name_to_share, _ = get_name_to_share(alpha)\n",
    "    # sorted in descending order\n",
    "    names_sorted_by_loc = [pair[0] for pair in sorted(name_to_loc.items(), key=lambda x: x[1], reverse=True)]\n",
    "    loc_sum = 0\n",
    "    for n in name_to_loc:\n",
    "        loc_sum += name_to_loc[n]\n",
    "    \n",
    "    ys, xs = [], []\n",
    "    for idx, n in enumerate(names_sorted_by_loc):\n",
    "        xs.append(idx)\n",
    "        y = name_to_share[n] * loc_sum / name_to_loc[n]\n",
    "        ys.append(y)\n",
    "    \n",
    "    plt.plot(xs, ys, 'o')\n",
    "    plt.ylim((0, 2))\n",
    "    plt.show()\n",
    "    \n",
    "    return xs, ys\n",
    "\n",
    "for alpha in [0.2, 0.8]:\n",
    "    xs, ys = figure3(alpha)\n",
    "    write_dots_to_csv(xs, ys, \"../temp/%s-fig3-%.2f.csv\" % (repo_name, alpha), \"LocRank,DevRank\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fig5 in the paper: DevRank scaled by commit type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "0：bug\n",
    "1: improvement\n",
    "2: feature\n",
    "3: maintenance\n",
    "\"\"\"\n",
    "\n",
    "c2t, c2pt = None, None\n",
    "with open('../data/commit2type.pickle', 'rb') as pf:\n",
    "    c2t = pickle.load(pf)\n",
    "with open('../data/predict_commit2type.pickle', 'rb') as pf:\n",
    "    c2pt = pickle.load(pf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relative_share_lists(alpha, sha_to_type, weight_vectors = [[1, 1, 1, 1]]):\n",
    "    orig_n2s, _ = get_name_to_share(alpha)\n",
    "    # sorted in descending order\n",
    "    sorted_names = [pair[0] for pair in sorted(orig_n2s.items(), key=lambda x: x[1], reverse=True)]\n",
    "    results = []\n",
    "    for coefs in weight_vectors:\n",
    "        n2s, _ = get_name_to_share(alpha, sha_to_type=sha_to_type, coefs=coefs)\n",
    "        relative_shares = [n2s[n] / orig_n2s[n] for n in sorted_names if orig_n2s[n]]\n",
    "        results.append(relative_shares)\n",
    "    return results\n",
    "\n",
    "ALPHA = 0.8\n",
    "WEIGHTS = [[2, 1, 1, 1], [1, 1, 2, 1]] # 2x bug, 2x feature\n",
    "\n",
    "pred = get_relative_share_lists(ALPHA, c2pt[repo_name])\n",
    "scaled = get_relative_share_lists(ALPHA, c2t[repo_name], WEIGHTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def fig5_preview(headers, columns):\n",
    "    for col in columns:\n",
    "        plt.plot(range(len(col)), col, 'o')\n",
    "    plt.ylim((0, 3))\n",
    "    plt.legend(headers, loc='best')\n",
    "    plt.show()\n",
    "\n",
    "def fig5_csv(headers, columns, file_name):\n",
    "    with open(file_name, 'w') as f:\n",
    "        f.write('Developers,')\n",
    "        for h in headers:\n",
    "            f.write(h + ',')\n",
    "        f.write('\\n')\n",
    "        for i in range(len(columns[0])):\n",
    "            f.write(str(i) + ',')\n",
    "            for col in columns:\n",
    "                f.write(str(col[i]) + ',')\n",
    "            f.write('\\n')\n",
    "\n",
    "fig5_preview(['bug x 2', 'feature x 2'], scaled)\n",
    "fig5_csv(['bug$\\\\\\\\times2$', 'feature$\\\\\\\\times2$'], scaled, 'dev-context-' + repo_name + '.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy of predicting committers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table 1 in the paper\n",
    "# Committer prediction performance of CommitRank, LocRank, and DevRank\n",
    "\n",
    "k = len(committer_names)\n",
    "\n",
    "name_to_share, _ = get_name_to_share(0.8)\n",
    "top_k_devrank = get_top_k(name_to_share, k)\n",
    "top_k_locrank = get_top_k(name_to_loc, k)\n",
    "top_k_nocrank = get_top_k(name_to_noc, k)\n",
    "\n",
    "print(\"DevRank accuracy: \", len(set(top_k_devrank).intersection(committer_names)) / k)\n",
    "print(\"LocRank accuracy: \", len(set(top_k_locrank).intersection(committer_names)) / k)\n",
    "print(\"NocRank accuracy: \", len(set(top_k_nocrank).intersection(committer_names)) / k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_to_share, _ = get_name_to_share(0.2)\n",
    "top_2k_devrank = get_top_k(name_to_share, 2 * k)\n",
    "top_2k_locrank = get_top_k(name_to_loc, 2 * k)\n",
    "top_2k_nocrank = get_top_k(name_to_noc, 2 * k)\n",
    "\n",
    "print(\"DevRank recall: \", len(set(top_2k_devrank).intersection(committer_names)) / k)\n",
    "print(\"LocRank recall: \", len(set(top_2k_locrank).intersection(committer_names)) / k)\n",
    "print(\"NocRank recall: \", len(set(top_2k_nocrank).intersection(committer_names)) / k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = range(1, len(name_to_share) + 1)\n",
    "ys_loc = []\n",
    "ys_dev = []\n",
    "for k in xs:\n",
    "    top_k_devrank = set(get_top_k(name_to_share, k))\n",
    "    top_k_locrank = set(get_top_k(name_to_loc, k))\n",
    "    ys_dev.append(len(top_k_devrank.intersection(committer_names)))\n",
    "    ys_loc.append(len(top_k_locrank.intersection(committer_names)))\n",
    "plt.plot(xs, ys_dev, color='b', label=\"DevRank\")\n",
    "plt.plot(xs, ys_loc, color='r', label=\"LocRank\")\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mismatch between Apache Roster and Analysis Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Only run this cell if you're analyzing apr repo\n",
    "roster_spelling = [\"Branko Čibej\", \"William A. Rowe Jr.\", \"Gregg Lewis Smith\", \"André Malo\"]\n",
    "repo_spelling = [\"Branko Cibej\", \"William A. Rowe Jr\", \"Gregg L. Smith\", \"Andre Malo\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Only run this cell if you're analyzing httpd repo\n",
    "roster_spelling = [\"André Malo\", \"Ask Bjørn Hansen\", \"William A. Rowe Jr.\"]\n",
    "repo_spelling = [\"Andre Malo\", \"Ask Bjorn Hansen\", \"William A. Rowe Jr\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Only run this cell if you're analyzing flink repo\n",
    "roster_spelling = ['Ufuk Celebi']\n",
    "repo_spelling = ['uce']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix different spelling between repo and apache roster\n",
    "for i in range(len(roster_spelling)):\n",
    "    committer_names.remove(roster_spelling[i])\n",
    "    committer_names.add(repo_spelling[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare names in analysis result with names in roster\n",
    "sorted_name_to_share = sorted(name_to_share.items(), key=lambda x: x[1], reverse=True)\n",
    "name_to_devrank = {}\n",
    "for idx, pair in enumerate(sorted_name_to_share, 1):\n",
    "    name_to_devrank[pair[0]] = idx\n",
    "    \n",
    "apache_only = committer_names - set(name_to_devrank.keys())\n",
    "repo_only = set(name_to_devrank.keys()) - committer_names\n",
    "print(\"Number of people present in Apache roster but absent from analysis result: \", len(apache_only))\n",
    "#pp.pprint(apache_only)\n",
    "print(\"Number of people present in analysis result but absent in Apache roster: \", len(repo_only))\n",
    "#pp.pprint(repo_only)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Coefficient and Significance Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_alpha = 0.05\n",
    "step = 0.05\n",
    "for i in range(19):\n",
    "    alpha = initial_alpha + step * i\n",
    "    name_to_share, _ = get_name_to_share(alpha)\n",
    "\n",
    "    truth = {}\n",
    "    for n in name_to_share:\n",
    "        if n in committer_names:\n",
    "            if n in pmc_names:\n",
    "                truth[n] = 2\n",
    "            else:\n",
    "                truth[n] = 1\n",
    "\n",
    "    truth_lst = []\n",
    "    pred_lst = []\n",
    "    loc_lst = []\n",
    "    for n in truth:\n",
    "        truth_lst.append(truth[n])\n",
    "        pred_lst.append(name_to_share[n])\n",
    "        loc_lst.append(name_to_loc[n])\n",
    "\n",
    "    print(\"Alpha: %.2f\" % alpha, spearmanr(truth_lst, pred_lst))\n",
    "    # print(\"Alpha: %.2f\" % alpha, spearmanr(pred_lst, loc_lst))\n",
    "    # print(\"Alpha: %.2f\" % alpha, kendalltau(pred_lst, truth_lst))\n",
    "    # print(\"Alpha: %.2f\" % alpha, kendalltau(pred_lst, loc_lst))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gini Coefficients over Alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_alpha = 0.05\n",
    "step = 0.05\n",
    "for i in range(19):\n",
    "    alpha = initial_alpha + step * i\n",
    "    name_to_share, _ = get_name_to_share(alpha)\n",
    "    \n",
    "    print(\"Overall Gini: %.2f\" % alpha, get_gini(name_to_share))\n",
    "    top = sorted(name_to_share.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "    print(\"Top Gini: %.2f\" % alpha, gini(numpy.array([x[1] for x in top])))\n",
    "    pp.pprint(top)\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
