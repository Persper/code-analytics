{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import subprocess\n",
    "import os\n",
    "import time\n",
    "import pdb\n",
    "from git import Repo\n",
    "from numpy import linalg as LA\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from lxml import etree\n",
    "from commit_graph import initialize_repo, get_contents\n",
    "from run_srcml import transform_dir, transform_src_to_tree\n",
    "from patch_parser import PatchParser\n",
    "from detect_change import get_changed_functions\n",
    "from write_graph_to_dot import write_G_to_dot_with_pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ns = {'srcml': 'http://www.srcML.org/srcML/src', 'pos': 'http://www.srcML.org/srcML/position'}\n",
    "\n",
    "def handle_function(func_node):\n",
    "    \"\"\"Given a <function> node, \n",
    "    return function name and function range (start & end lineno)\"\"\"\n",
    "    \n",
    "    name_node = func_node.find('srcml:name', ns)\n",
    "    func_name, start_line = handle_name(name_node)\n",
    "    if not func_name or not start_line:\n",
    "        print('Function name/start not found!') # very unlikely to happen\n",
    "        return None, None, None\n",
    "    \n",
    "    block_node = func_node.find('srcml:block', ns)\n",
    "    if not block_node:\n",
    "        try:\n",
    "            block_node = func_node.xpath('./following-sibling::srcml:block', namespaces=ns)[0]\n",
    "        except:\n",
    "            print(\"More edge cases for block node! (in function {})\".format(func_name))\n",
    "            return func_name, None, None\n",
    "    try:\n",
    "        pos_node = block_node.find('pos:position', ns)\n",
    "        end_line = int(pos_node.attrib['{http://www.srcML.org/srcML/position}line'])\n",
    "    except:\n",
    "        print(\"Block node doesn't have position node inside!\")\n",
    "        return func_name, None, None\n",
    "    \n",
    "    return func_name, start_line, end_line\n",
    "\n",
    "def handle_name(name_node):\n",
    "    \"\"\"Given an <name> node, \n",
    "    return its text content and position (line)\"\"\"\n",
    "    text, line = None, None\n",
    "    if name_node:\n",
    "        text = name_node.text\n",
    "        line = int(name_node.attrib['{http://www.srcML.org/srcML/position}line'])\n",
    "    return text, line\n",
    "\n",
    "class NotFunctionCallError(Exception):\n",
    "    \"\"\"Raise for false positive <call> nodes\"\"\"\n",
    "\n",
    "def handle_call(call_node):\n",
    "    \"\"\"Given an <call> node, return function name being called\n",
    "    \n",
    "    Throws NotFunctionCallException\n",
    "    \n",
    "    Case 1: casting function pointer is not function call\n",
    "        Example: tmp.sa_handler = (void (*)(int)) handler;\n",
    "        \n",
    "    Case 2: function call from struct variable\n",
    "        Example: tty->write(tty)\n",
    "        \n",
    "    \"\"\"\n",
    "    name_node = call_node.find('srcml:name', ns) \n",
    "    if not name_node:\n",
    "        # Case 1\n",
    "        raise NotFunctionCallError()\n",
    "    callee_name = name_node.text\n",
    "    if not callee_name:\n",
    "        # Case 2\n",
    "        callee_name = name_node[-1].text\n",
    "    return callee_name\n",
    "\n",
    "def remove_edges_of_node(G, n):\n",
    "    \"\"\"Remove all edges of n, but keep the node itself in the graph\n",
    "    \n",
    "    >>> G3 = nx.DiGraph()\n",
    "    >>> G3.add_path([0, 1, 2, 3, 4])\n",
    "    >>> remove_edges_of_node(G3, 2)\n",
    "    >>> G3.nodes()\n",
    "    [0, 1, 2, 3, 4]\n",
    "    >>> G3.edges()\n",
    "    [(0, 1), (3, 4)]\n",
    "    \n",
    "    \"\"\"\n",
    "    try:\n",
    "        nbrs = G.succ[n]\n",
    "    except KeyError: # NetworkXError if not in self\n",
    "        # raise NetworkXError(\"The node %s is not in the digraph.\"%(n, ))\n",
    "        print(\"The node %s is not in the digraph.\"%(n, ))\n",
    "        return \n",
    "    for u in nbrs:\n",
    "        del G.pred[u][n]\n",
    "    G.succ[n] = {}\n",
    "    for u in G.pred[n]:\n",
    "        del G.succ[u][n]\n",
    "    G.pred[n] = {}\n",
    "    \n",
    "def get_func_ranges_c(root):\n",
    "    func_ranges, func_names = [], []\n",
    "    for func_node in root.findall('./srcml:function', namespaces=ns):\n",
    "        \n",
    "        func_name, start_line, end_line = handle_function(func_node)\n",
    "        if not (func_name and start_line and end_line):\n",
    "            continue\n",
    "        \n",
    "        func_ranges.append([start_line, end_line])\n",
    "        func_names.append(func_name)\n",
    "    return func_names, func_ranges\n",
    "    \n",
    "def update_call_graph(roots, change_info, G):\n",
    "    for func_name in change_info:\n",
    "        if func_name in G:\n",
    "            remove_edges_of_node(G, func_name)\n",
    "            G.node[func_name]['num_lines'] += change_info[func_name]\n",
    "        \n",
    "    # here roots should be constructed from new commit\n",
    "    # info of new functions is added to change_info\n",
    "    build_call_graph(roots, change_info, G)\n",
    "        \n",
    "\n",
    "def build_call_graph(roots, change_info, G=None):\n",
    "    if G == None:\n",
    "        G = nx.DiGraph()\n",
    "        \n",
    "    func_to_file = {}\n",
    "    for root in roots:\n",
    "        # print('------ ' + root.attrib['filename'] + ' ------')\n",
    "        \n",
    "        for func_node in root.findall('./srcml:function', namespaces=ns):                \n",
    "            \n",
    "            caller_name, start_line, end_line = handle_function(func_node)\n",
    "            if not caller_name:\n",
    "                continue\n",
    "                \n",
    "            if start_line and end_line:\n",
    "                num_lines = end_line - start_line + 1\n",
    "            else:\n",
    "                # default num_lines is 1\n",
    "                num_lines = 1\n",
    "                \n",
    "            if caller_name not in G: # this is new function\n",
    "                change_info[caller_name] = num_lines\n",
    "                G.add_node(caller_name, {'num_lines': num_lines, 'defined': True}) \n",
    "            elif not G.node[caller_name]['defined']: # already in G, but haven't seen definition \n",
    "                G.node[caller_name]['defined'] = True\n",
    "                G.node[caller_name]['num_lines'] = num_lines\n",
    "                \n",
    "            func_to_file[caller_name] = root.attrib['filename']\n",
    "            \n",
    "            # handle all function calls\n",
    "            for call_node in func_node.xpath('.//srcml:call', namespaces=ns):\n",
    "                \n",
    "                try:\n",
    "                    callee_name = handle_call(call_node)\n",
    "                except NotFunctionCallError:\n",
    "                    continue\n",
    "                except:\n",
    "                    print(\"Callee name not found! (in function {})\".format(caller_name))\n",
    "                    continue\n",
    "                \n",
    "                if callee_name not in G:\n",
    "                    G.add_node(callee_name, {'num_lines': 1, 'defined': False})\n",
    "                G.add_edge(caller_name, callee_name)\n",
    "                \n",
    "    return G, func_to_file\n",
    "\n",
    "\n",
    "def devrank(G, count_self=False, alpha=0.85, epsilon=1e-5, max_iters=300):\n",
    "    ni = {}\n",
    "    for i, u in enumerate(G):\n",
    "        ni[u] = i\n",
    "        \n",
    "    sizes = {}\n",
    "    universe_size = 0\n",
    "    for u in G:\n",
    "        sizes[u] = G.node[u]['num_lines']\n",
    "        universe_size += sizes[u]\n",
    "        \n",
    "    num_nodes = len(G.nodes())\n",
    "    P = np.zeros([num_nodes, num_nodes])\n",
    "    \n",
    "    for u in G:\n",
    "        num_out_edges = len(G[u])\n",
    "        if num_out_edges == 0:\n",
    "            P[:, ni[u]] = 1 / num_nodes\n",
    "        else:\n",
    "            total_out_sizes = 0\n",
    "            for v in G[u]:\n",
    "                total_out_sizes += sizes[v]\n",
    "            if count_self:\n",
    "                total_out_sizes += sizes[u]\n",
    "                P[ni[u], ni[u]] = sizes[u] / total_out_sizes\n",
    "            for v in G[u]:\n",
    "                P[ni[v], ni[u]] = sizes[v] / total_out_sizes\n",
    "            \n",
    "    p = np.empty(num_nodes)\n",
    "    for u in G:\n",
    "        p[ni[u]] = sizes[u] / universe_size\n",
    "\n",
    "    v = np.ones(num_nodes) / num_nodes\n",
    "        \n",
    "    for i in range(max_iters):\n",
    "        new_v = alpha * np.dot(P, v) + (1 - alpha) * p\n",
    "        assert(new_v.shape == (num_nodes,))\n",
    "        delta = new_v - v\n",
    "        if LA.norm(delta) < epsilon:\n",
    "            break\n",
    "        v = new_v\n",
    "        \n",
    "    pr = {}\n",
    "    for u in G:\n",
    "        pr[u] = v[ni[u]]\n",
    "    \n",
    "    return pr\n",
    "\n",
    "def draw_call_graph(G, pr):\n",
    "    pr = pagerank(G.reverse())\n",
    "    write_G_to_dot_with_pr(G, pr, 'linux_test.dot', header_lines=['nodesep=1.0;\\n'])\n",
    "    subprocess.call('unflatten -l 8 -f -o unflattened_linux_test.dot linux_test.dot', shell=True)\n",
    "    subprocess.call('dot -Tsvg unflattened_linux_test.dot -o unflattened_linux_test.svg', shell=True)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Beaver/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:33: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "/Users/Beaver/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:14: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "/Users/Beaver/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:41: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 5130\n",
      "Number of edges: 13514\n",
      "Number of connected components: 172\n"
     ]
    }
   ],
   "source": [
    "c_roots = []\n",
    "for xml in glob.glob('linux-kernel-xml/kernel/*.c.xml'):\n",
    "    tree = etree.parse(xml)\n",
    "    c_roots.append(tree.getroot())\n",
    "G, func_to_file = build_call_graph(c_roots, {})\n",
    "print(\"Number of nodes: {}\".format(len(G.nodes())))\n",
    "print(\"Number of edges: {}\".format(len(G.edges())))\n",
    "print(\"Number of connected components: {}\".format(nx.number_weakly_connected_components(G)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('copy_process', 0.0053585420494072821, 'linux-kernel/kernel/fork.c'),\n",
       " ('audit_receive_msg', 0.0038208782997065272, 'linux-kernel/kernel/audit.c'),\n",
       " ('sched_init', 0.003207014716320017, 'linux-kernel/kernel/sched.c'),\n",
       " ('audit_filter_rules',\n",
       "  0.0030091465021866255,\n",
       "  'linux-kernel/kernel/auditsc.c'),\n",
       " ('audit_log_exit', 0.0029762928232642616, 'linux-kernel/kernel/auditsc.c'),\n",
       " ('futex_requeue', 0.0029456188527405376, 'linux-kernel/kernel/futex.c'),\n",
       " ('get_signal_to_deliver',\n",
       "  0.0023601726701005864,\n",
       "  'linux-kernel/kernel/signal.c'),\n",
       " ('wait_task_zombie', 0.002336110733253982, 'linux-kernel/kernel/exit.c'),\n",
       " ('generate_sched_domains',\n",
       "  0.002308769373404837,\n",
       "  'linux-kernel/kernel/cpuset.c'),\n",
       " ('rcu_torture_init',\n",
       "  0.0023046420441189845,\n",
       "  'linux-kernel/kernel/rcutorture.c'),\n",
       " ('load_balance', 0.0021772356794441598, 'linux-kernel/kernel/sched.c'),\n",
       " ('posix_cpu_timer_set',\n",
       "  0.0021430203058164692,\n",
       "  'linux-kernel/kernel/posix-cpu-timers.c'),\n",
       " ('kgdb_handle_exception',\n",
       "  0.0020964021966879774,\n",
       "  'linux-kernel/kernel/kgdb.c'),\n",
       " ('__lock_acquire', 0.0020524009280741069, 'linux-kernel/kernel/lockdep.c'),\n",
       " ('audit_data_to_entry',\n",
       "  0.0020299444071902348,\n",
       "  'linux-kernel/kernel/auditfilter.c'),\n",
       " ('select_task_rq_fair',\n",
       "  0.001999223601220174,\n",
       "  'linux-kernel/kernel/sched_fair.c'),\n",
       " ('register_console', 0.0019733506291657065, 'linux-kernel/kernel/printk.c'),\n",
       " ('rt_mutex_adjust_prio_chain',\n",
       "  0.0019731719689666935,\n",
       "  'linux-kernel/kernel/rtmutex.c'),\n",
       " ('do_syslog', 0.001957575631733972, 'linux-kernel/kernel/printk.c'),\n",
       " ('do_exit', 0.0019567691739771718, 'linux-kernel/kernel/exit.c')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr = devrank(G, alpha=0.01)\n",
    "sorted_pr = sorted(pr.items(), key=lambda x: x[1])\n",
    "# draw_call_graph(G)\n",
    "[(x[0], x[1], func_to_file[x[0]] if x[0] in func_to_file else 'Unknown') for x in reversed(sorted_pr[-20:])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class RepoAnalyzer():\n",
    "    \n",
    "    def __init__(self, repo_path):\n",
    "        self.repo_path = repo_path\n",
    "        self.repo = initialize_repo(repo_path)\n",
    "        self.git = self.repo.git # directly using git\n",
    "        self.git.checkout('v2.6.32', '-f')\n",
    "        self.commits = list(self.repo.iter_commits()) # first element is the latest commit\n",
    "        self.G = nx.DiGraph()\n",
    "        self.exts = ('.c',)\n",
    "        self.history = {}\n",
    "        self.share = {}\n",
    "        self.patch_parser = PatchParser()\n",
    "        self.EMPTY_TREE_SHA = \"4b825dc642cb6eb9a060e54bf8d69288fbee4904\"\n",
    "\n",
    "        \n",
    "    def evolve(self, num_commits, verbose=False):\n",
    "        # handle first commit\n",
    "        \n",
    "        \"\"\"\n",
    "        first_commit = self.commits[-1]\n",
    "        sha = first_commit.hexsha\n",
    "        self.git.checkout(sha, '-f')\n",
    "        xml_output_path = self.repo_path + \"-xml-\" + sha[:6]\n",
    "        transform_dir(self.repo_path, xml_output_path, self.exts)\n",
    "        roots = []\n",
    "        for ext in self.exts:\n",
    "            for xml_file in glob.glob(xml_output_path + \"/**/*.xml\"):\n",
    "                roots.append(etree.parse(xml_file).getroot())\n",
    "                \n",
    "        build_call_graph(roots, {}, G=self.G)\n",
    "        \"\"\"\n",
    "        self.G = nx.DiGraph()\n",
    "        self.history = {}\n",
    "        start = time.time()\n",
    "        counter = 1\n",
    "        for commit in reversed(self.commits[-num_commits:]):\n",
    "            sha = commit.hexsha\n",
    "            roots = []\n",
    "            self.history[sha] = {}\n",
    "            print('------  No.{} {} ------'.format(counter, sha))\n",
    "            if counter % 20 == 0:\n",
    "                print('-------- Used time: {} --------'.format(time.time() - start))\n",
    "            \n",
    "            if not commit.parents:\n",
    "                diff_index = commit.diff(self.EMPTY_TREE_SHA, create_patch=True, R=True)\n",
    "            else:\n",
    "                last_commit = commit.parents[0]\n",
    "                diff_index = commit.diff(last_commit, create_patch=True, R=True)\n",
    "            \n",
    "            for diff in diff_index:\n",
    "                if diff.new_file:\n",
    "                    diff.change_type = 'A'\n",
    "                elif diff.deleted_file:\n",
    "                    diff.change_type = 'D'\n",
    "                elif diff.renamed: \n",
    "                    diff.change_type = 'R'\n",
    "                elif diff.a_blob and diff.b_blob and diff.a_blob != diff.b_blob:\n",
    "                    diff.change_type = 'M'\n",
    "                else:\n",
    "                    diff.change_type = 'U'\n",
    "                    print(\"Take a look at this commit!!! {}\".format(sha))\n",
    "                    # raise Exception('Non-existent Change Type!')\n",
    "                    continue\n",
    "            \n",
    "            if verbose:\n",
    "                print(\"{}:{}\".format(sha, \" \".join([diff.change_type for diff in diff_index])))\n",
    "            \n",
    "            for diff in diff_index:\n",
    "                if diff.change_type == 'U':\n",
    "                    continue\n",
    "                    \n",
    "                if diff.change_type == 'A':\n",
    "                    fname = diff.b_blob.path\n",
    "                    if self.fname_filter(fname):\n",
    "                        file_contents = get_contents(self.repo, commit, fname)\n",
    "                        root = transform_src_to_tree(file_contents)\n",
    "                        if not root:\n",
    "                            continue\n",
    "                        roots.append(root)\n",
    "                    \n",
    "                elif diff.change_type == 'D':\n",
    "                    fname = diff.a_blob.path\n",
    "                    if self.fname_filter(fname):\n",
    "                        additions, deletions = self.parse_patch(diff.diff)\n",
    "                        if not (additions and deletions):\n",
    "                            continue\n",
    "                            \n",
    "                        file_contents = get_contents(self.repo, last_commit, fname)\n",
    "                        root = transform_src_to_tree(file_contents)\n",
    "                        if not root:\n",
    "                            continue\n",
    "                            \n",
    "                        func_names, func_ranges = get_func_ranges_c(root)\n",
    "                        change_info = get_changed_functions(func_names, func_ranges, additions, deletions)\n",
    "                        for func_name in change_info:\n",
    "                            self.history[sha][func_name] = change_info[func_name]\n",
    "                        \n",
    "                        # no roots.append for change_type 'D'\n",
    "                        \n",
    "                elif diff.change_type == 'R':\n",
    "                    new_fname = diff.rename_to\n",
    "                    old_fname = diff.rename_from\n",
    "                    if self.fname_filter(new_fname) or self.fname_filter(old_fname):\n",
    "                        additions, deletions = self.parse_patch(diff.diff)\n",
    "                        if not (additions and deletions):\n",
    "                            continue\n",
    "                            \n",
    "                        old_file_contents = get_contents(self.repo, last_commit, old_fname)\n",
    "                        old_root = transform_src_to_tree(old_file_contents)\n",
    "                        if not old_root:\n",
    "                            continue\n",
    "                        \n",
    "                        func_names, func_ranges = get_func_ranges_c(old_root)\n",
    "                        change_info = get_changed_functions(func_names, func_ranges, additions, deletions)\n",
    "                        for func_name in change_info:\n",
    "                            self.history[sha][func_name] = change_info[func_name]\n",
    "                            \n",
    "                        new_file_contents = get_contents(self.repo, commit, new_fname)\n",
    "                        new_root = transform_src_to_tree(new_file_contents)\n",
    "                        if not new_root:\n",
    "                            continue\n",
    "                            \n",
    "                        roots.append(new_root)\n",
    "                else:\n",
    "                    fname = diff.b_blob.path\n",
    "                    if self.fname_filter(fname):\n",
    "                        additions, deletions = self.parse_patch(diff.diff)\n",
    "                        if not (additions and deletions):\n",
    "                            continue\n",
    "                            \n",
    "                        old_file_contents = get_contents(self.repo, last_commit, fname)\n",
    "                        old_root = transform_src_to_tree(old_file_contents)\n",
    "                        if not old_root:\n",
    "                            continue\n",
    "                        \n",
    "                        func_names, func_ranges = get_func_ranges_c(old_root)\n",
    "                        change_info = get_changed_functions(func_names, func_ranges, additions, deletions)\n",
    "                        for func_name in change_info:\n",
    "                            self.history[sha][func_name] = change_info[func_name]\n",
    "                            \n",
    "                        new_file_contents = get_contents(self.repo, commit, fname)\n",
    "                        new_root = transform_src_to_tree(new_file_contents)\n",
    "                        if not new_root:\n",
    "                            continue\n",
    "                            \n",
    "                        roots.append(new_root)\n",
    "                        \n",
    "            update_call_graph(roots, self.history[sha], self.G)\n",
    "            counter += 1\n",
    "                        \n",
    "                        \n",
    "                        \n",
    "    def parse_patch(self, patch):\n",
    "        additions, deletions = None, None\n",
    "        try:\n",
    "            additions, deletions = self.patch_parser.parse(patch.decode(\"utf-8\"))\n",
    "        except UnicodeDecodeError:\n",
    "            print(\"UnicodeDecodeError in function parse_patch!\")\n",
    "        except:\n",
    "            pdb.set_trace()\n",
    "            print(\"Unknown error in function parse_patch!\")\n",
    "        return additions, deletions\n",
    "                    \n",
    "                    \n",
    "        \n",
    "    def fname_filter(self, fname):\n",
    "        for ext in self.exts:\n",
    "            if not fname.endswith(ext):\n",
    "                return False\n",
    "        return True\n",
    "        \n",
    "        \n",
    "    def update_shares(self):\n",
    "        pr = devrank(self.G, alpha=0.1)\n",
    "        for sha in self.history:\n",
    "            self.share[sha] = 0\n",
    "            for func_name in self.history[sha]:\n",
    "                self.share[sha] = (self.history[sha][func_name] / self.G.node[func_name]['num_lines']) * pr[func_name]    \n",
    "        \n",
    "    def top_commits(n):\n",
    "        pass\n",
    "\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "analyzer = RepoAnalyzer('linux-kernel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------  No.1 9417d4148f0ddc5ee2cc1114ce97c71c5e4cb4b7 ------\n",
      "------  No.2 d62bd5409667a8d2445942415a626947a1befd24 ------\n",
      "------  No.3 9b7e85e9f4c289c98d8d8c0389fd6f79844a6f5f ------\n",
      "------  No.4 eb619203065fb78cb27270be426853057d6f472a ------\n",
      "UnicodeDecodeError in function parse_patch!\n",
      "------  No.5 5b3842b9350f4c3b1898eb1ef5e5c4f45b8f889e ------\n",
      "UnicodeEncodeError in transform_src_to_tree!\n",
      "------  No.6 9a29bd96634bc105476885ee82fb31992e4b89b5 ------\n",
      "UnicodeEncodeError in transform_src_to_tree!\n",
      "------  No.7 ffc26fa924e2eca8ca5be2108b52b97269a6e512 ------\n",
      "UnicodeEncodeError in transform_src_to_tree!\n",
      "------  No.8 d204cc8e2a8629d2a44fd5d9bb9a4b54cf46556c ------\n",
      "UnicodeEncodeError in transform_src_to_tree!\n",
      "Block node doesn't have position node inside!\n",
      "------  No.9 fe3eb15b85f38d60574a10860ed7e30f2db743e9 ------\n",
      "------  No.10 c9da70101a8cee9027388191535c557448301779 ------\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "analyzer.evolve(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "analyzer.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[(n, analyzer.G.node[n]['num_lines']) for n in analyzer.G.nodes()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "analyzer.G.node['write_pipe']['num_lines']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "analyzer.update_shares()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sorted(analyzer.share.items(), key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_node_to_src(node, s=None):\n",
    "    if s == None:\n",
    "        s = \"\"\n",
    "    if node.text:\n",
    "        s += node.text\n",
    "    for child in node:\n",
    "        s = transform_node_to_src(child, s)\n",
    "    if node.tail:\n",
    "        s += node.tail\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
